ğŸš€ CUDA Particle Filter â€“ GPU Capstone Project
ğŸ“Œ Overview

This project implements a CUDA-accelerated Particle Filter for real-time state estimation and tracking.
The objective is to demonstrate how GPU parallelism significantly improves performance by processing thousands of particles simultaneously.

All major stages of the particle filter run on the GPU:

Initialization

Propagation

Weight update

Normalization

Resampling

This project was developed as part of the GPU Specialization Capstone.

ğŸ§  Algorithm Summary

A particle filter estimates the state of a system using many random samples called particles.

Each iteration performs:

Propagation
Updates each particle using a motion model.

Update
Computes how well each particle matches the measurement.

Normalization
Scales all weights so their sum equals 1.

Resampling
Generates a new particle set based on weight distribution.

GPU parallelism assigns one thread per particle, enabling massive speedup over CPU implementations.

ğŸ“‚ Project Structure
.
â”œâ”€â”€ main.cu
â”œâ”€â”€ particle_filter.cu
â”œâ”€â”€ particle_filter.cuh
â”œâ”€â”€ pgm_images.zip
â””â”€â”€ README.md

âš™ï¸ Requirements

NVIDIA GPU

CUDA Toolkit (12.4+ recommended)

Linux / WSL / Google Colab

nvcc compiler

ğŸ”§ Compilation
nvcc -o particle_filter main.cu particle_filter.cu

â–¶ï¸ Execution
./particle_filter


If arguments are required:

./particle_filter input_file particle_count

ğŸ“Š Sample Output
Init time (ms): 11.3092
Iter 0 â€” prop: 0.007 ms, update: 0.003 ms, norm: 0.003 ms, resamp: 0.003 ms
Iter 1 â€” prop: 0.003 ms, update: 0.004 ms, norm: 0.003 ms, resamp: 0.003 ms
Iter 2 â€” prop: 0.004 ms, update: 0.003 ms, norm: 0.003 ms, resamp: 0.003 ms
...
Iter 9 â€” prop: 0.004 ms, update: 0.003 ms, norm: 0.003 ms, resamp: 0.003 ms
Done.

Output Explanation

Init time â†’ GPU memory setup & initialization

prop â†’ particle propagation

update â†’ weight computation

norm â†’ weight normalization

resamp â†’ particle resampling

Each iteration completes in ~0.012 ms, proving efficient GPU acceleration.

ğŸ–¼ Test Data

The repository includes 10 synthetic PGM images:

256Ã—256 grayscale images

Stored in pgm_images.zip

Used for benchmarking and testing

ğŸ“ˆ Performance Highlights

One GPU thread per particle

Sub-millisecond kernel execution

Efficient scaling with particle count

Minimal host-device transfers

ğŸ§ª What I Learned

CUDA kernel design

GPU memory management

Parallel reduction

Performance profiling

Kernel optimization strategies

ğŸ”® Future Work

Real sensor / camera input

Shared memory optimization

Thrust-based prefix sum resampling

Visualization of particle movement

Multi-GPU scaling

ğŸ¯ Conclusion

This project demonstrates how GPU computing transforms particle filtering from a slow CPU process into a real-time parallel system.
It highlights CUDAâ€™s power for scientific and robotics applications.

ğŸ‘¤ Author

Utkarsh Mishra
GPU Specialization Capstone Project
